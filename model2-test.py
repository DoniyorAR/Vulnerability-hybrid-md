import pandas as pd
import openai
from sklearn.metrics import f1_score, precision_score, recall_score
from sklearn.preprocessing import LabelEncoder

# Load your API key from an environment variable or secure storage
openai.api_key = 'your_openai_api_key_here'

def load_data(filename):
    """
    Load the dataset containing code snippets, their programming language, and ground truth labels.
    """
    return pd.read_csv(filename)

def preprocess_text(texts):
    """
    Basic preprocessing of the code text. This can be adjusted based on specific needs.
    Stripping whitespace and handling special characters if needed.
    """
    processed_texts = [text.strip() for text in texts]
    return processed_texts

def create_prompt(code, language):
    """
    Create the prompt for the GPT-4.0 API by adjusting it to ask specifically if the code is vulnerable or safe,
    expecting a single-word answer.
    """
    return f"Is this code written in {language} vulnerable or safe? Just give me an answer, vulnerable or safe."

def query_openai_gpt4(prompt):
    """
    Send a prompt to the OpenAI API and return the response.
    This function interacts with the OpenAI API using the specified engine and settings.
    """
    try:
        response = openai.Completion.create(
            engine="text-davinci-002",  # Consider updating to the latest model
            prompt=prompt,
            max_tokens=10,  # We expect a single-word answer
            temperature=0  # Setting temperature to 0 for deterministic output
        )
        return response.choices[0].text.strip().lower()
    except openai.error.OpenAIError as e:
        return f"An error occurred: {str(e)}"

def compute_metrics(actuals, predictions):
    """
    Compute and return the F1-score, precision, and recall between actual and predicted labels.
    """
    f1 = f1_score(actuals, predictions, pos_label='vulnerable')
    precision = precision_score(actuals, predictions, pos_label='vulnerable')
    recall = recall_score(actuals, predictions, pos_label='vulnerable')
    return f1, precision, recall

def main():
    # Load and preprocess the dataset
    df = load_data('data.csv')
    df['code'] = preprocess_text(df['code'])

    # Adding predictions to the DataFrame
    df['predicted_safety'] = df.apply(lambda row: query_openai_gpt4(create_prompt(row['code'], row['language'])), axis=1)

    # Encode labels for metric calculation
    le = LabelEncoder()
    df['safety'] = le.fit_transform(df['safety'])  # Encoding labels as integers
    df['predicted_safety'] = le.transform(df['predicted_safety'])  # Encode predictions similarly

    # Compute metrics
    f1, precision, recall = compute_metrics(df['safety'], df['predicted_safety'])
    print(f"F1-Score: {f1}, Precision: {precision}, Recall: {recall}")

    # Print the DataFrame for review
    print(df)

    # Optionally, save the DataFrame to a new CSV file
    df.to_csv('updated_data_with_predictions.csv', index=False)

if __name__ == "__main__":
    main()
